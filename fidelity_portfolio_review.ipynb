{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Fidelity Portfolio Review\n",
    "### V 0.2.0\n",
    "\n",
    "## What does it do?\n",
    "\n",
    "This notebook imports data from a csv of account positions, copies the data into a new excel workbook, and fills in additional columns with additional information, such as P/E Ratios, Recognia Technical Analysis, etc.\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "This notebook uses the Selenium Webdriver to automate Firefox to navigate through Fidelity's stock research pages and extract useful information. \n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Selenium V 3.141.0\n",
    "- Gecko Webdriver installed in system path\n",
    "- Pandas\n",
    "- Numpy\n",
    "\n",
    "\n",
    "## Instructions for use\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from datetime import datetime\n",
    "import extract\n",
    "import shutil\n",
    "# import yfinance\n",
    "\n",
    "# import the csv file:\n",
    "\n",
    "# at this time, I'm unsure if I want to continue using TK to open the csv file; last time I tried, it froze up my notebook.\n",
    "\n",
    "# root = Tk()\n",
    "# root.withdraw()\n",
    "# source_data = askopenfilename()\n",
    "# for now, just use the direct file path\n",
    "stock_df = pd.read_csv('test_data.csv', index_col=False)\n",
    "stock_df = stock_df.sort_values('Symbol')\n",
    "\n",
    "# add the necessary columns to the df for the data we will be extracting\n",
    "columns_list = ['Symbol', 'Description', 'Quantity', 'Last Price', 'Last Price Change', 'Current Value', \"Today's Gain/Loss Dollar\", \"Today's Gain/Loss Percent\", \"Total Gain/Loss Dollar\", \"Total Gain/Loss Percent\", \"Percent Of Account\", \"Cost Basis\", \"Cost Basis Per Share\", 'Div. Amt', 'Div. Yield', 'Equity Summary Score', 'Recognia Short Term', 'Recognia Intermediate Term', 'Recognia Long Term', 'Valuation', 'Quality', 'Growth Stability', 'Financial Health', '1-Yr Price Target', 'P/E TTM', 'P/E 5-Yr Avg', 'P/CF Recent Quarter', 'P/CF TTM', 'P/Sales Recent Quarter', 'P/Sales TTM', 'P/B', 'Debt/Equity TTM', 'Debt/Equity Recent Quarter', '52-Week Performance', \"Account Name/Number\"]\n",
    "stock_df = stock_df.reindex(columns = columns_list)\n",
    "\n",
    "current_time = datetime.now().strftime('%m%d%y_%H%M%S')\n",
    "new_workbook = f'target_workbook_{current_time}.xlsx'\n",
    "\n",
    "# make a copy of the target_workbook w/ the datetime in the name\n",
    "# NOTE: not needed, since conditional formatting needs to be applied directly w/ openpyxl\n",
    "# shutil.copy2('target_workbook.xlsx', new_workbook)\n",
    "\n",
    "# next step: copy the existing data into the new excel document\n",
    "# we will be periodically overwriting this notebook\n",
    "# this will serve as backup for our data if the extract cell crashes\n",
    "stock_df.to_excel(new_workbook)\n",
    "\n",
    "# after that, open the web browser\n",
    "driver = Firefox()\n",
    "driver.get('https://www.fidelity.com/')\n",
    "driver.execute_script('''window.open(\"https://finance.yahoo.com/quote/V?p=V&.tsrc=fin-srch\", \"_blank\");''')\n",
    "fidelity_window = driver.window_handles[0]\n",
    "yf_window = driver.window_handles[1]\n",
    "driver.switch_to.window(window_name=fidelity_window)\n"
   ]
  },
  {
   "source": [
    "## Next,\n",
    "Log into Fidelity's website as you normally would. Once you have logged on to Fidelity's website, you can run the data extraction cell below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "must be a MF\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "must be a MF\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "Must not be a MF either, can't find anything\n",
      "must be a MF\n",
      "Must not be a MF either, can't find anything\n",
      "must be a MF\n",
      "Must not be a MF either, can't find anything\n",
      "DF saved to Excel File\n"
     ]
    }
   ],
   "source": [
    "# create a list of symbols to iterate over\n",
    "# symbols = [i for i in stock_df['Symbol']]\n",
    "\n",
    "# define a prev_symbol variable to save time\n",
    "prev_symbol = \"\"\n",
    "\n",
    "# var set to control when to save to excel\n",
    "i = 0\n",
    "error_count = 0\n",
    "\n",
    "# iterate thru the symbols and write to the DF\n",
    "for row in stock_df.itertuples():\n",
    "    \n",
    "    if (stock_df.iloc[i, 33] > 0) | (stock_df.iloc[i, 33] < 0):\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    symbol = row[1]\n",
    "\n",
    "    if symbol == 'Pending Activity':\n",
    "        i += 1\n",
    "        continue\n",
    "    elif symbol == 'SPAXX**':\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # check to see if we already have data for the symbol\n",
    "\n",
    "        \n",
    "    # GIANT try/except block (tbh too big)\n",
    "    # if we run into a 'NoSuchElementException', we go to the fidelity homepage, then try reloading the page\n",
    "    # the while loop is used in case of an error that causes the page to get reloaded; that way, it doesn't skip symbols and place data in the wrong place (hopefully)\n",
    "    \n",
    "    success = False\n",
    "\n",
    "    while success is False:\n",
    "    \n",
    "        try:\n",
    "\n",
    "            # load the page, and scroll thru it\n",
    "            driver.execute_script(\"window.scrollTo(0, 0)\")\n",
    "\n",
    "            driver.get(f\"https://snapshot.fidelity.com/fidresearch/snapshot/landing.jhtml#/research?symbol={symbol}&appCode=&optInNRE=\")\n",
    "            time.sleep(5)   # pauses may need to be adjusted based on network connection\n",
    "            driver.execute_script(\"window.scrollTo(0, 0)\")\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(\"window.scrollTo(0,(document.body.scrollHeight / 2))\")\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "\n",
    "            # now, check the security type\n",
    "            sec_type = extract.determine_security_type(driver)\n",
    "            if sec_type == 'Stocks':\n",
    "\n",
    "                # Dividends\n",
    "                dividends = extract.stock_div_yield(driver)\n",
    "                stock_df.at[row.Index, 'Div. Amt'] = dividends[0]\n",
    "                stock_df.at[row.Index, 'Div. Yield'] = dividends[1]\n",
    "\n",
    "                # Equity Summary Score\n",
    "                try:\n",
    "                    equity_sum_score = extract.stock_equity_sum_score(driver)\n",
    "                except:\n",
    "                    equity_sum_score = np.nan\n",
    "                stock_df.at[row.Index, 'Equity Summary Score'] = equity_sum_score\n",
    "\n",
    "                # Recognia Technical Analysis\n",
    "                recognia_dict = extract.recognia_analysis(driver, sec_type)\n",
    "                stock_df.loc[row.Index, 'Recognia Short Term'] = recognia_dict['Recognia Short Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Intermediate Term'] = recognia_dict['Recognia Intermediate Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Long Term'] = recognia_dict['Recognia Long Term']\n",
    "\n",
    "                # Stock Valuation\n",
    "                valuation = extract.stock_valuation(driver)\n",
    "                stock_df.at[row.Index, 'Valuation'] = valuation\n",
    "\n",
    "                # Stock Quality\n",
    "                quality = extract.stock_quality(driver)\n",
    "                stock_df.at[row.Index, 'Quality'] = quality\n",
    "\n",
    "                # Stock Growth Stability\n",
    "                growth_stability = extract.stock_growth_stability(driver)\n",
    "                stock_df.at[row.Index, 'Growth Stability'] = growth_stability\n",
    "\n",
    "                # Stock Financial Health\n",
    "                financial_health = extract.stock_financial_health(driver)\n",
    "                stock_df.at[row.Index, 'Financial Health'] = financial_health\n",
    "\n",
    "                # 52-Week Performance\n",
    "                ftw_perf = extract.stock_growth_stability(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # Key Stats\n",
    "                # I'm honestly not sure if this will work\n",
    "                key_stats = extract.stock_key_stats(driver, symbol)\n",
    "                try: \n",
    "                    stock_df.at[row.Index, 'P/E TTM'] = key_stats[0]['P/E (Trailing Twelve Months)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/E 5-Yr Avg'] = key_stats[0]['P/E (5-Year Average)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E 5-Yr Avg'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF Recent Quarter'] = key_stats[0]['Price/Cash Flow (Most Recent Quarter)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF Recent Quarter'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF TTM'] = key_stats[0]['Price/Cash Flow (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales Recent Quarter'] = key_stats[0]['Price/Cash Flow (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales Recent Quarter'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales TTM'] = key_stats[0]['Price/Sales (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/B'] = key_stats[0]['Price/Book']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/B'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Debt/Equity TTM'] = key_stats[1]['Total Debt/Equity (Most Recent Quarter, Annualized)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Debt/Equity TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Debt/Equity Recent Quarter'] = key_stats[1]['Total Debt/Equity (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Debt/Equity Recent Quarter'] = np.nan\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 1-Yr Price Target\n",
    "                try:\n",
    "                    price_target = extract.stock_one_yr_price_target(driver, symbol)\n",
    "                except IndexError:\n",
    "                    price_target = np.nan\n",
    "                stock_df.at[row.Index, '1-Yr Price Target'] = price_target\n",
    "\n",
    "            elif sec_type == 'ETFs':\n",
    "                \n",
    "                # ETF Stats\n",
    "                etf_stats = extract.etf_key_stats(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/E TTM'] = etf_stats['Price / Earnings (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/B'] = etf_stats['Price / Book']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/B'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales TTM'] = etf_stats['Price / Sales']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF TTM'] = etf_stats['Price / Cash Flow']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Div. Yield'] = etf_stats['etf_distribution_yield']  # changed this recently to better reflect what the actual function returns\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Div. Yield'] = np.nan\n",
    "\n",
    "                # ETF Recognia\n",
    "                try:\n",
    "                    recognia_dict = extract.recognia_analysis(driver, sec_type)\n",
    "                except IndexError:\n",
    "                    recognia_dict = {\n",
    "                        'Recognia Short Term': np.nan,\n",
    "                        'Recognia Intermediate Term': np.nan,\n",
    "                        'Recognia Long Term': np.nan\n",
    "                    }\n",
    "                stock_df.loc[row.Index, 'Recognia Short Term'] = recognia_dict['Recognia Short Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Intermediate Term'] = recognia_dict['Recognia Intermediate Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Long Term'] = recognia_dict['Recognia Long Term']\n",
    "\n",
    "                # ETF 52 Week Performance\n",
    "                ftw_perf = extract.etf_52_week_perf(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except ValueError:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "            elif sec_type == 'Mutual Funds':\n",
    "\n",
    "                # 52 Week Performance\n",
    "                ftw_perf = extract.mf_52_week_perf(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except ValueError:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "        \n",
    "            success = True\n",
    "            i += 1\n",
    "            if (i % 5) == 0:\n",
    "                stock_df.to_excel(new_workbook)\n",
    "                print('DF saved to Excel File')\n",
    "            prev_symbol = symbol\n",
    "            # prev_series = stock_df.iloc[row.Index, 13:34]\n",
    "            prev_row = row.Index\n",
    "            error_count = 0\n",
    "\n",
    "        except (NoSuchElementException, IndexError) as e:\n",
    "            driver.get(\"https://www.fidelity.com/\")\n",
    "            time.sleep(10)\n",
    "            error_count += 1\n",
    "            if error_count > 3:\n",
    "                i += 1\n",
    "                success = True\n",
    "stock_df.to_excel(new_workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reopen the browser in case of a crash:\n",
    "driver = Firefox()\n",
    "driver.get('https://www.fidelity.com/')\n",
    "driver.execute_script('''window.open(\"https://finance.yahoo.com/quote/V?p=V&.tsrc=fin-srch\", \"_blank\");''')\n",
    "fidelity_window = driver.window_handles[0]\n",
    "yf_window = driver.window_handles[1]\n",
    "driver.switch_to.window(window_name=fidelity_window)"
   ]
  },
  {
   "source": [
    "## Data Cleaning Cells\n",
    "\n",
    "### Converting values to floats\n",
    "\n",
    "Use the cell below to remove the dollar signs, commas, and other characters that get in the way of converting as many columns to floats as possible."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to reopen your workbook later for further analysis, run this cell\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from datetime import datetime\n",
    "import extract\n",
    "import shutil\n",
    "\n",
    "new_workbook = 'target_workbook_030721_174609.xlsx'\n",
    "stock_df = pd.read_excel(new_workbook, 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideally, we'd load this function in earlier\n",
    "def convert_to_float(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub('[\\$,%+]', '', value)\n",
    "        if value == \"--\":\n",
    "            value = np.nan\n",
    "    return np.float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to convert the strings from the fidelity sheet to np.floats\n",
    "stock_df_cleaned = stock_df.copy()\n",
    "try:\n",
    "    stock_df_cleaned = stock_df_cleaned.drop(columns=['Unnamed: 0'])    # this is for when the file is manually reloaded, as it occasionally creates duplicate unnecessary columns that cause problems\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    stock_df_cleaned = stock_df_cleaned.drop(columns=['Unnamed: 0.1'])\n",
    "except:\n",
    "    pass\n",
    "for i in range(3, 13):\n",
    "    stock_df_cleaned.iloc[:, i] = stock_df_cleaned.apply(lambda x: convert_to_float(x[i]), axis=1)\n",
    "stock_df_cleaned.to_excel(new_workbook)"
   ]
  },
  {
   "source": [
    "### Missing Data\n",
    "\n",
    "Next, Look through the data and ensure that any symbol that appears twice has the same extracted data in each row"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: a fix applied to the data extraction cell may render this cell unnecessary;\n",
    "\n",
    "# looks for rows where the same symbol have missing values from the webscraped data, and copies the data from the row w/ the least nan values.\n",
    "\n",
    "# compile a list of symbols that fit this criteria\n",
    "errors = []\n",
    "prev_symbol = ''\n",
    "for row in stock_df_cleaned.itertuples():\n",
    "    symbol = row[1]\n",
    "    if symbol == 'Pending Activity':\n",
    "        continue\n",
    "    elif symbol == 'SPAXX**':\n",
    "        continue\n",
    "    row_data = row[14:35]\n",
    "    if symbol == prev_symbol:\n",
    "        if row[0] == 1:\n",
    "            prev_symbol = symbol\n",
    "            prev_row_data = row_data\n",
    "            continue\n",
    "        for i in range(0, len(row_data)):\n",
    "            if row_data[i] != prev_row_data[i]:\n",
    "                if symbol not in errors:\n",
    "                    errors.append(symbol)\n",
    "                break\n",
    "    prev_symbol = symbol\n",
    "    prev_row_data = row_data\n",
    "\n",
    "# go through this list and copy the data appropriately\n",
    "# tests for developing the data cleaning for rows of duplicate symbols where some have data and some do not\n",
    "for symbol in errors:\n",
    "    dict_01 = dict()\n",
    "    indicies = stock_df_cleaned[stock_df_cleaned['Symbol'] == symbol].index\n",
    "    for index in indicies:\n",
    "        dict_01[index] = stock_df_cleaned.iloc[index, 13:34]    # create a dict where key is the index #, and the value is a tuple of values we're looking for\n",
    "    dict_02 = dict()    # this dict contains the index # as the key and the # of nan's in that row\n",
    "    for k, v in dict_01.items():\n",
    "        dict_02[k] = 0\n",
    "        for index, val in v.iteritems():\n",
    "            if isinstance(val, np.float64):\n",
    "                if (np.isnan(val)) == True:\n",
    "                    try: \n",
    "                        dict_02[k] = dict_02[k] + 1\n",
    "                    except:\n",
    "                        dict_02[k] = 1\n",
    "    least_nan = -1\n",
    "    least_nan_index = -1\n",
    "    for k, v in dict_02.items():    # see which k has the least # of nan's; that one will write to all of the other indicies\n",
    "        if least_nan == -1:\n",
    "            least_nan = v\n",
    "            least_nan_index = k\n",
    "        elif v < least_nan:\n",
    "            least_nan_index = k\n",
    "            least_nan = v\n",
    "    for index in indicies:\n",
    "        if least_nan_index != index:\n",
    "            stock_df_cleaned.iloc[index, 13:34] = stock_df_cleaned.iloc[least_nan_index, 13:34]\n",
    "            "
   ]
  },
  {
   "source": [
    "## Conditional Formatting\n",
    "\n",
    "### Apply Conditional Formatting to Values in certain columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Color, PatternFill, Font\n",
    "from openpyxl.formatting import Rule\n",
    "from openpyxl.styles.differential import DifferentialStyle\n",
    "from openpyxl.formatting.rule import ColorScaleRule, CellIsRule, FormulaRule\n",
    "\n",
    "# load workbook\n",
    "wb = load_workbook(filename='target_workbook_030921_083456.xlsx')\n",
    "portfolio = wb.active\n",
    "num_rows = portfolio.max_row\n",
    "\n",
    "# formats fundamental analyses\n",
    "valuation_rule = ColorScaleRule(start_type='num', start_value=0, start_color='BE2525',\n",
    "mid_type='num', mid_value=50, mid_color='e5ff00',\n",
    "end_type='num', end_value=100, end_color='25BE25')\n",
    "\n",
    "portfolio.conditional_formatting.add(f'U2:U{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'V2:V{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'W2:W{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'X2:X{num_rows}', valuation_rule)\n",
    "\n",
    "# format total gain/loss percent\n",
    "portfolio.conditional_formatting.add(f'K2:K{num_rows}', ColorScaleRule(start_type='num', start_value=0, start_color='BE2525',\n",
    "mid_type='num', mid_value=4.5, mid_color='e5ff00',\n",
    "end_type='num', end_value=8, end_color='25BE25'))\n",
    "\n",
    "# format percentage of acct\n",
    "portfolio.conditional_formatting.add(f'L2:L{num_rows}', ColorScaleRule(start_type='num', start_value=0, start_color='25BE25',\n",
    "mid_type='num', mid_value=2.5, mid_color='e5ff00',\n",
    "end_type='num', end_value=3.5, end_color='be2525'))\n",
    "\n",
    "# equity summary score\n",
    "portfolio.conditional_formatting.add(f\"Q2:Q{num_rows}\", ColorScaleRule(start_type='num', start_value=0, start_color='be2525',\n",
    "mid_type='num', mid_value=5, mid_color='e5ff00',\n",
    "end_type='num', end_value=10, end_color='25be25'))\n",
    "\n",
    "# recognia technical analysis\n",
    "# if weak\n",
    "text_color_weak = Font(color='f9e9e9')\n",
    "text_highlight_weak = PatternFill(bgColor='be2525')\n",
    "dxf_weak = DifferentialStyle(font=text_color_weak, fill=text_highlight_weak)\n",
    "weak_rule = Rule(type='containsText', operator='containsText', text='weak', dxf=dxf_weak)\n",
    "weak_rule.formula = ['NOT(ISERROR(SEARCH(\"weak\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', weak_rule)\n",
    "\n",
    "# if neutral\n",
    "text_color_neutral = Font(color='000000')\n",
    "text_highlight_neutral = PatternFill(bgColor='e5ff00')\n",
    "dxf_neutral = DifferentialStyle(font=text_color_neutral, fill=text_highlight_neutral)\n",
    "neutral_rule = Rule(type='containsText', operator='containsText', text='neutral', dxf=dxf_neutral)\n",
    "neutral_rule.formula = ['NOT(ISERROR(SEARCH(\"neutral\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', neutral_rule)\n",
    "\n",
    "# if strong\n",
    "text_color_strong = Font(color='e9f9e9')\n",
    "text_highlight_strong = PatternFill(bgColor='25be25')\n",
    "dxf_strong = DifferentialStyle(font=text_color_strong, fill=text_highlight_strong)\n",
    "strong_rule = Rule(type='containsText', operator='containsText', text='strong', dxf=dxf_strong)\n",
    "strong_rule.formula = ['NOT(ISERROR(SEARCH(\"strong\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', strong_rule)\n",
    "\n",
    "# price target\n",
    "# if price target is greater than current price\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='greaterThan', formula=[f'E2:E{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='25be25',\n",
    "    end_color='25be25',\n",
    "    fill_type='solid'\n",
    ")))\n",
    "\n",
    "# if price target less than current price\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='lessThan', formula=[f'E2:E{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='be2525',\n",
    "    end_color='be2525',\n",
    "    fill_type='solid'\n",
    ")))\n",
    "\n",
    "'''# if none present\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='notContains', formula=[f'Y2:Y{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='FFFFFF',\n",
    "    end_color='FFFFFF',\n",
    "    fill_type='solid'\n",
    ")))'''\n",
    "\n",
    "wb.save(\"target_workbook_030921_083456_formatted.xlsx\")"
   ]
  },
  {
   "source": [
    "# EVERYTHING BELOW THIS CELL IS TO BE DELETED BEFORE THIS NOTEBOOK IS FINISHED"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test; delete when finished\n",
    "for row in stock_df.itertuples():\n",
    "    print(row.Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # test cell\n",
    " stock_df.loc[100, 'Cost Basis Per Share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cell\n",
    "test_dict = {\n",
    "    'test': 50\n",
    "}\n",
    "\n",
    "other_dict = {\n",
    "    1: test_dict\n",
    "}\n",
    "other_dict[1]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cell\n",
    "# use df.at for strings?\n",
    "stock_df.at[65, 'Equity Summary Score'] = 0\n",
    "stock_df.loc[65, 'Recognia Short Term'] = 'weak'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.iloc[49, 13:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([1, 100, 55], dtype='int64')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "stock_df[stock_df['Symbol'] == 'AAPL'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Div. Amt                         0.82\n",
       "Div. Yield                       0.68\n",
       "Equity Summary Score              9.2\n",
       "Recognia Short Term              weak\n",
       "Recognia Intermediate Term       weak\n",
       "Recognia Long Term            neutral\n",
       "Valuation                          74\n",
       "Quality                            90\n",
       "Growth Stability                   88\n",
       "Financial Health                   73\n",
       "1-Yr Price Target              151.75\n",
       "P/E TTM                         32.88\n",
       "P/E 5-Yr Avg                    18.82\n",
       "P/CF Recent Quarter             16.25\n",
       "P/CF TTM                        27.68\n",
       "P/Sales Recent Quarter          27.68\n",
       "P/Sales TTM                      7.04\n",
       "P/B                             29.35\n",
       "Debt/Equity TTM                169.19\n",
       "Debt/Equity Recent Quarter     168.37\n",
       "52-Week Performance                88\n",
       "Name: 100, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "stock_df.iloc[stock_df[stock_df['Symbol'] == 'AAPL'].index[0], 13:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.iloc[2,13:34] = stock_df.iloc[0, 13:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "type(stock_df.iloc[16, 33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'strip'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a108d376e705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m010.42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "test_text = 1,010.42\n",
    "test_text.strip(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1010.42'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "text = '1,010.42'\n",
    "text = re.sub('[\\$,]', '', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.to_excel(new_workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Last Price Last Price Change\n",
       "1      $121.26            +$0.27\n",
       "100    $121.26            +$0.27\n",
       "55     $121.26            +$0.27\n",
       "101     $36.87            +$0.31\n",
       "56      $36.87            +$0.31\n",
       "..         ...               ...\n",
       "118     $46.13            -$0.03\n",
       "71      $46.13            -$0.03\n",
       "157        NaN               NaN\n",
       "158        NaN               NaN\n",
       "159        NaN               NaN\n",
       "\n",
       "[160 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Last Price</th>\n      <th>Last Price Change</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>$121.26</td>\n      <td>+$0.27</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>$121.26</td>\n      <td>+$0.27</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>$121.26</td>\n      <td>+$0.27</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>$36.87</td>\n      <td>+$0.31</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>$36.87</td>\n      <td>+$0.31</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>$46.13</td>\n      <td>-$0.03</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>$46.13</td>\n      <td>-$0.03</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>160 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "stock_df_cleaned.iloc[0:, 3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([136, 82, 37], dtype='int64')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "stock_df_cleaned[stock_df_cleaned['Symbol'] == 'LOW'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['BIV',\n",
       " 'BSV',\n",
       " 'CNRG',\n",
       " 'DIA',\n",
       " 'DSI',\n",
       " 'FAN',\n",
       " 'FCOR',\n",
       " 'FDEEX',\n",
       " 'FDHY',\n",
       " 'FLTB',\n",
       " 'ICLN',\n",
       " 'IEF',\n",
       " 'ISTB',\n",
       " 'IWC',\n",
       " 'JMBS',\n",
       " 'LBRDA',\n",
       " 'LOW',\n",
       " 'MBB',\n",
       " 'MMM',\n",
       " 'MSFT',\n",
       " 'NVDA',\n",
       " 'NXST',\n",
       " 'PBW',\n",
       " 'QQQ',\n",
       " 'SHM',\n",
       " 'SLGN',\n",
       " 'SPY',\n",
       " 'SUSA',\n",
       " 'TAIL',\n",
       " 'TAN',\n",
       " 'TLT',\n",
       " 'VIG',\n",
       " 'VWO',\n",
       " 'VWOB',\n",
       " 'VYM',\n",
       " 'XYLD']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "errors = []\n",
    "prev_symbol = ''\n",
    "for row in stock_df_cleaned.itertuples():\n",
    "    symbol = row[1]\n",
    "    if symbol == 'Pending Activity':\n",
    "        continue\n",
    "    elif symbol == 'SPAXX**':\n",
    "        continue\n",
    "    row_data = row[14:35]\n",
    "    if symbol == prev_symbol:\n",
    "        if row[0] == 1:\n",
    "            prev_symbol = symbol\n",
    "            prev_row_data = row_data\n",
    "            continue\n",
    "        for i in range(0, len(row_data)):\n",
    "            if row_data[i] != prev_row_data[i]:\n",
    "                if symbol not in errors:\n",
    "                    errors.append(symbol)\n",
    "                break\n",
    "    prev_symbol = symbol\n",
    "    prev_row_data = row_data\n",
    "errors"
   ]
  },
  {
   "source": [
    "# tests for developing the data cleaning for rows of duplicate symbols where some have data and some do not\n",
    "for symbol in errors:\n",
    "    dict_01 = dict()\n",
    "    indicies = stock_df_cleaned[stock_df_cleaned['Symbol'] == symbol].index\n",
    "    for index in indicies:\n",
    "        dict_01[index] = stock_df_cleaned.iloc[index, 13:34]    # create a dict where key is the index #, and the value is a tuple of values we're looking for\n",
    "    dict_02 = dict()    # this dict contains the index # as the key and the # of nan's in that row\n",
    "    for k, v in dict_01.items():\n",
    "        dict_02[k] = 0\n",
    "        for index, val in v.iteritems():\n",
    "            if isinstance(val, np.float64):\n",
    "                if (np.isnan(val)) == True:\n",
    "                    try: \n",
    "                        dict_02[k] = dict_02[k] + 1\n",
    "                    except:\n",
    "                        dict_02[k] = 1\n",
    "    least_nan = -1\n",
    "    least_nan_index = -1\n",
    "    for k, v in dict_02.items():    # see which k has the least # of nan's; that one will write to all of the other indicies\n",
    "        if least_nan == -1:\n",
    "            least_nan = v\n",
    "            least_nan_index = k\n",
    "        elif v < least_nan:\n",
    "            least_nan_index = k\n",
    "            least_nan = v\n",
    "    for index in indicies:\n",
    "        if least_nan_index != index:\n",
    "            stock_df_cleaned.iloc[index, 13:34] = stock_df_cleaned.iloc[least_nan_index, 13:34]\n",
    "            "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Div. Amt                         0.82\n",
       "Div. Yield                       0.68\n",
       "Equity Summary Score              9.2\n",
       "Recognia Short Term              weak\n",
       "Recognia Intermediate Term       weak\n",
       "Recognia Long Term            neutral\n",
       "Valuation                          74\n",
       "Quality                            90\n",
       "Growth Stability                   88\n",
       "Financial Health                   73\n",
       "1-Yr Price Target              151.75\n",
       "P/E TTM                         32.88\n",
       "P/E 5-Yr Avg                    18.82\n",
       "P/CF Recent Quarter             16.25\n",
       "P/CF TTM                        27.68\n",
       "P/Sales Recent Quarter          27.68\n",
       "P/Sales TTM                      7.04\n",
       "P/B                             29.35\n",
       "Debt/Equity TTM                169.19\n",
       "Debt/Equity Recent Quarter     168.37\n",
       "52-Week Performance                88\n",
       "Name: 1, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "stock_df_cleaned.iloc[0, 13:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "type(stock_df_cleaned.iloc[84, 19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing above cell w/ just one symbol to see how it works w/o having to click the next line button one million times\n",
    "symbol = 'LOW'\n",
    "dict_01 = dict()\n",
    "indicies = stock_df_cleaned[stock_df_cleaned['Symbol'] == symbol].index\n",
    "for index in indicies:\n",
    "    dict_01[index] = stock_df_cleaned.iloc[index, 13:34]    # create a dict where key is the index #, and the value is a tuple of values we're looking for\n",
    "dict_02 = dict()    # this dict contains the index # as the key and the # of nan's in that row\n",
    "for k, v in dict_01.items():\n",
    "    dict_02[k] = 0\n",
    "    for index, val in v.iteritems():\n",
    "        if isinstance(val, np.float64):\n",
    "            if (np.isnan(val)) == True:\n",
    "                try: \n",
    "                    dict_02[k] = dict_02[k] + 1\n",
    "                except:\n",
    "                    dict_02[k] = 1\n",
    "least_nan = -1\n",
    "least_nan_index = -1\n",
    "for k, v in dict_02.items():    # see which k has the least # of nan's; that one will write to all of the other indicies\n",
    "    if least_nan == -1:\n",
    "        least_nan = v\n",
    "        least_nan_index = k\n",
    "    elif v < least_nan:\n",
    "        least_nan_index = k\n",
    "        least_nan = v\n",
    "for index in indicies:\n",
    "    if least_nan_index != index:\n",
    "        stock_df_cleaned.iloc[index, 13:34] = stock_df_cleaned.iloc[least_nan_index, 13:34]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
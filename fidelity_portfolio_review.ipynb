{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Fidelity Portfolio Review\n",
    "### V 0.2.0\n",
    "\n",
    "## What does it do?\n",
    "\n",
    "This notebook imports data from a csv of account positions, copies the data into a new excel workbook, and fills in additional columns with additional information, such as P/E Ratios, Recognia Technical Analysis, etc.\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "This notebook uses the Selenium Webdriver to automate Firefox to navigate through Fidelity's stock research pages and extract useful information. \n",
    "\n",
    "After extracting the data, other cells can be run to clean the data, add conditional formatting to an excel document containing the data, and (coming soon) perform visualization with the data.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Selenium V 3.141.0\n",
    "- Gecko Webdriver installed in system path\n",
    "- Pandas\n",
    "- Numpy\n",
    "\n",
    "\n",
    "## Instructions for use\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from datetime import datetime\n",
    "import extract\n",
    "import shutil\n",
    "# import yfinance\n",
    "\n",
    "def convert_to_float(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub('[\\$,%+]', '', value)\n",
    "        if value == \"--\":\n",
    "            value = np.nan\n",
    "    return np.float(value)\n",
    "\n",
    "# import the csv file:\n",
    "\n",
    "# at this time, I'm unsure if I want to continue using TK to open the csv file; last time I tried, it froze up my notebook.\n",
    "\n",
    "# root = Tk()\n",
    "# root.withdraw()\n",
    "# source_data = askopenfilename()\n",
    "# for now, just use the direct file path\n",
    "stock_df = pd.read_csv('test_data.csv', index_col=False)\n",
    "stock_df = stock_df.sort_values('Symbol')\n",
    "\n",
    "# add the necessary columns to the df for the data we will be extracting\n",
    "columns_list = ['Symbol', 'Description', 'Quantity', 'Last Price', 'Last Price Change', 'Current Value', \"Today's Gain/Loss Dollar\", \"Today's Gain/Loss Percent\", \"Total Gain/Loss Dollar\", \"Total Gain/Loss Percent\", \"Percent Of Account\", \"Cost Basis\", \"Cost Basis Per Share\", 'Div. Amt', 'Div. Yield', 'Equity Summary Score', 'Recognia Short Term', 'Recognia Intermediate Term', 'Recognia Long Term', 'Valuation', 'Quality', 'Growth Stability', 'Financial Health', '1-Yr Price Target', 'P/E TTM', 'P/E 5-Yr Avg', 'P/CF Recent Quarter', 'P/CF TTM', 'P/Sales Recent Quarter', 'P/Sales TTM', 'P/B', 'Debt/Equity TTM', 'Debt/Equity Recent Quarter', '52-Week Performance', \"Account Name/Number\"]\n",
    "stock_df = stock_df.reindex(columns = columns_list)\n",
    "\n",
    "current_time = datetime.now().strftime('%m%d%y_%H%M%S')\n",
    "new_workbook = f'target_workbook_{current_time}.xlsx'\n",
    "\n",
    "# make a copy of the target_workbook w/ the datetime in the name\n",
    "# NOTE: not needed, since conditional formatting needs to be applied directly w/ openpyxl\n",
    "# shutil.copy2('target_workbook.xlsx', new_workbook)\n",
    "\n",
    "# next step: copy the existing data into the new excel document\n",
    "# we will be periodically overwriting this notebook\n",
    "# this will serve as backup for our data if the extract cell crashes\n",
    "stock_df.to_excel(new_workbook)\n",
    "\n",
    "# after that, open the web browser\n",
    "driver = Firefox()\n",
    "driver.get('https://www.fidelity.com/')\n",
    "driver.execute_script('''window.open(\"https://finance.yahoo.com/quote/V?p=V&.tsrc=fin-srch\", \"_blank\");''')\n",
    "fidelity_window = driver.window_handles[0]\n",
    "yf_window = driver.window_handles[1]\n",
    "driver.switch_to.window(window_name=fidelity_window)\n"
   ]
  },
  {
   "source": [
    "## Next,\n",
    "Log into Fidelity's website as you normally would. Once you have logged on to Fidelity's website, you can run the data extraction cell below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "must be a MF\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "must be a MF\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "DF saved to Excel File\n",
      "must be a MF\n",
      "Must not be a MF either, can't find anything\n",
      "must be a MF\n",
      "Must not be a MF either, can't find anything\n",
      "must be a MF\n",
      "Must not be a MF either, can't find anything\n",
      "DF saved to Excel File\n"
     ]
    }
   ],
   "source": [
    "# create a list of symbols to iterate over\n",
    "# symbols = [i for i in stock_df['Symbol']]\n",
    "\n",
    "# define a prev_symbol variable to save time\n",
    "prev_symbol = \"\"\n",
    "\n",
    "# var set to control when to save to excel\n",
    "i = 0\n",
    "error_count = 0\n",
    "\n",
    "# iterate thru the symbols and write to the DF\n",
    "for row in stock_df.itertuples():\n",
    "    \n",
    "    if (stock_df.iloc[i, 33] > 0) | (stock_df.iloc[i, 33] < 0):\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    symbol = row[1]\n",
    "\n",
    "    if symbol == 'Pending Activity':\n",
    "        i += 1\n",
    "        continue\n",
    "    elif symbol == 'SPAXX**':\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # check to see if we already have data for the symbol\n",
    "\n",
    "        \n",
    "    # GIANT try/except block (tbh too big)\n",
    "    # if we run into a 'NoSuchElementException', we go to the fidelity homepage, then try reloading the page\n",
    "    # the while loop is used in case of an error that causes the page to get reloaded; that way, it doesn't skip symbols and place data in the wrong place (hopefully)\n",
    "    \n",
    "    success = False\n",
    "\n",
    "    while success is False:\n",
    "    \n",
    "        try:\n",
    "\n",
    "            # load the page, and scroll thru it\n",
    "            driver.execute_script(\"window.scrollTo(0, 0)\")\n",
    "\n",
    "            driver.get(f\"https://snapshot.fidelity.com/fidresearch/snapshot/landing.jhtml#/research?symbol={symbol}&appCode=&optInNRE=\")\n",
    "            time.sleep(5)   # pauses may need to be adjusted based on network connection\n",
    "            driver.execute_script(\"window.scrollTo(0, 0)\")\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(\"window.scrollTo(0,(document.body.scrollHeight / 2))\")\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "\n",
    "            # now, check the security type\n",
    "            sec_type = extract.determine_security_type(driver)\n",
    "            if sec_type == 'Stocks':\n",
    "\n",
    "                # Dividends\n",
    "                dividends = extract.stock_div_yield(driver)\n",
    "                stock_df.at[row.Index, 'Div. Amt'] = dividends[0]\n",
    "                stock_df.at[row.Index, 'Div. Yield'] = dividends[1]\n",
    "\n",
    "                # Equity Summary Score\n",
    "                try:\n",
    "                    equity_sum_score = extract.stock_equity_sum_score(driver)\n",
    "                except:\n",
    "                    equity_sum_score = np.nan\n",
    "                stock_df.at[row.Index, 'Equity Summary Score'] = equity_sum_score\n",
    "\n",
    "                # Recognia Technical Analysis\n",
    "                recognia_dict = extract.recognia_analysis(driver, sec_type)\n",
    "                stock_df.loc[row.Index, 'Recognia Short Term'] = recognia_dict['Recognia Short Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Intermediate Term'] = recognia_dict['Recognia Intermediate Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Long Term'] = recognia_dict['Recognia Long Term']\n",
    "\n",
    "                # Stock Valuation\n",
    "                valuation = extract.stock_valuation(driver)\n",
    "                stock_df.at[row.Index, 'Valuation'] = valuation\n",
    "\n",
    "                # Stock Quality\n",
    "                quality = extract.stock_quality(driver)\n",
    "                stock_df.at[row.Index, 'Quality'] = quality\n",
    "\n",
    "                # Stock Growth Stability\n",
    "                growth_stability = extract.stock_growth_stability(driver)\n",
    "                stock_df.at[row.Index, 'Growth Stability'] = growth_stability\n",
    "\n",
    "                # Stock Financial Health\n",
    "                financial_health = extract.stock_financial_health(driver)\n",
    "                stock_df.at[row.Index, 'Financial Health'] = financial_health\n",
    "\n",
    "                # 52-Week Performance\n",
    "                ftw_perf = extract.stock_growth_stability(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # Key Stats\n",
    "                # I'm honestly not sure if this will work\n",
    "                key_stats = extract.stock_key_stats(driver, symbol)\n",
    "                try: \n",
    "                    stock_df.at[row.Index, 'P/E TTM'] = key_stats[0]['P/E (Trailing Twelve Months)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/E 5-Yr Avg'] = key_stats[0]['P/E (5-Year Average)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E 5-Yr Avg'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF Recent Quarter'] = key_stats[0]['Price/Cash Flow (Most Recent Quarter)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF Recent Quarter'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF TTM'] = key_stats[0]['Price/Cash Flow (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales Recent Quarter'] = key_stats[0]['Price/Cash Flow (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales Recent Quarter'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales TTM'] = key_stats[0]['Price/Sales (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/B'] = key_stats[0]['Price/Book']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/B'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Debt/Equity TTM'] = key_stats[1]['Total Debt/Equity (Most Recent Quarter, Annualized)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Debt/Equity TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Debt/Equity Recent Quarter'] = key_stats[1]['Total Debt/Equity (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Debt/Equity Recent Quarter'] = np.nan\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 1-Yr Price Target\n",
    "                try:\n",
    "                    price_target = extract.stock_one_yr_price_target(driver, symbol)\n",
    "                except IndexError:\n",
    "                    price_target = np.nan\n",
    "                stock_df.at[row.Index, '1-Yr Price Target'] = price_target\n",
    "\n",
    "            elif sec_type == 'ETFs':\n",
    "                \n",
    "                # ETF Stats\n",
    "                etf_stats = extract.etf_key_stats(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/E TTM'] = etf_stats['Price / Earnings (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/B'] = etf_stats['Price / Book']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/B'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales TTM'] = etf_stats['Price / Sales']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF TTM'] = etf_stats['Price / Cash Flow']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Div. Yield'] = etf_stats['etf_distribution_yield']  # changed this recently to better reflect what the actual function returns\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Div. Yield'] = np.nan\n",
    "\n",
    "                # ETF Recognia\n",
    "                try:\n",
    "                    recognia_dict = extract.recognia_analysis(driver, sec_type)\n",
    "                except IndexError:\n",
    "                    recognia_dict = {\n",
    "                        'Recognia Short Term': np.nan,\n",
    "                        'Recognia Intermediate Term': np.nan,\n",
    "                        'Recognia Long Term': np.nan\n",
    "                    }\n",
    "                stock_df.loc[row.Index, 'Recognia Short Term'] = recognia_dict['Recognia Short Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Intermediate Term'] = recognia_dict['Recognia Intermediate Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Long Term'] = recognia_dict['Recognia Long Term']\n",
    "\n",
    "                # ETF 52 Week Performance\n",
    "                ftw_perf = extract.etf_52_week_perf(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except ValueError:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "            elif sec_type == 'Mutual Funds':\n",
    "\n",
    "                # 52 Week Performance\n",
    "                ftw_perf = extract.mf_52_week_perf(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except ValueError:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "        \n",
    "            success = True\n",
    "            i += 1\n",
    "            if (i % 5) == 0:\n",
    "                stock_df.to_excel(new_workbook)\n",
    "                print('DF saved to Excel File')\n",
    "            prev_symbol = symbol\n",
    "            # prev_series = stock_df.iloc[row.Index, 13:34]\n",
    "            prev_row = row.Index\n",
    "            error_count = 0\n",
    "\n",
    "        except (NoSuchElementException, IndexError) as e:\n",
    "            driver.get(\"https://www.fidelity.com/\")\n",
    "            time.sleep(10)\n",
    "            error_count += 1\n",
    "            if error_count > 3:\n",
    "                i += 1\n",
    "                success = True\n",
    "stock_df.to_excel(new_workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reopen the browser in case of a crash:\n",
    "driver = Firefox()\n",
    "driver.get('https://www.fidelity.com/')\n",
    "driver.execute_script('''window.open(\"https://finance.yahoo.com/quote/V?p=V&.tsrc=fin-srch\", \"_blank\");''')\n",
    "fidelity_window = driver.window_handles[0]\n",
    "yf_window = driver.window_handles[1]\n",
    "driver.switch_to.window(window_name=fidelity_window)"
   ]
  },
  {
   "source": [
    "# Data Cleaning Cells\n",
    "\n",
    "### Converting values to floats\n",
    "\n",
    "Use the cell below to remove the dollar signs, commas, and other characters that get in the way of converting as many columns to floats as possible."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is to only be used if you are doing your cleaning/analysis in a different session from extracting your data.\n",
    "# if you need to reopen your workbook later for further analysis, run this cell\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from datetime import datetime\n",
    "import extract\n",
    "import shutil\n",
    "\n",
    "def convert_to_float(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub('[\\$,%+]', '', value)\n",
    "        if value == \"--\":\n",
    "            value = np.nan\n",
    "    return np.float(value)\n",
    "\n",
    "new_workbook = 'target_workbook_030721_174609.xlsx'\n",
    "stock_df = pd.read_excel(new_workbook, 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideally, we'd load this function in earlier\n",
    "def convert_to_float(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub('[\\$,%+]', '', value)\n",
    "        if value == \"--\":\n",
    "            value = np.nan\n",
    "    return np.float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to convert the strings from the fidelity sheet to np.floats\n",
    "stock_df_cleaned = stock_df.copy()\n",
    "try:\n",
    "    stock_df_cleaned = stock_df_cleaned.drop(columns=['Unnamed: 0'])    # this is for when the file is manually reloaded, as it occasionally creates duplicate unnecessary columns that cause problems\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    stock_df_cleaned = stock_df_cleaned.drop(columns=['Unnamed: 0.1'])\n",
    "except:\n",
    "    pass\n",
    "for i in range(3, 13):\n",
    "    stock_df_cleaned.iloc[:, i] = stock_df_cleaned.apply(lambda x: convert_to_float(x[i]), axis=1)\n",
    "stock_df_cleaned.to_excel(new_workbook)"
   ]
  },
  {
   "source": [
    "## Missing Data\n",
    "\n",
    "If you notice that data inconsistencies between rows of the same symbol, this cell aims to correct that by taking the row with the least np.nan's and copying its data to the other rows of the same symbol. Do not run this if your data is already consistent.\n",
    "\n",
    "Next, Look through the data and ensure that any symbol that appears twice has the same extracted data in each row. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: a fix applied to the data extraction cell may render this cell unnecessary;\n",
    "\n",
    "# looks for rows where the same symbol have missing values from the webscraped data, and copies the data from the row w/ the least nan values.\n",
    "\n",
    "# compile a list of symbols that fit this criteria\n",
    "errors = []\n",
    "prev_symbol = ''\n",
    "for row in stock_df_cleaned.itertuples():\n",
    "    symbol = row[1]\n",
    "    if symbol == 'Pending Activity':\n",
    "        continue\n",
    "    elif symbol == 'SPAXX**':\n",
    "        continue\n",
    "    row_data = row[14:35]\n",
    "    if symbol == prev_symbol:\n",
    "        if row[0] == 1:\n",
    "            prev_symbol = symbol\n",
    "            prev_row_data = row_data\n",
    "            continue\n",
    "        for i in range(0, len(row_data)):\n",
    "            if row_data[i] != prev_row_data[i]:\n",
    "                if symbol not in errors:\n",
    "                    errors.append(symbol)\n",
    "                break\n",
    "    prev_symbol = symbol\n",
    "    prev_row_data = row_data\n",
    "\n",
    "# go through this list and copy the data appropriately\n",
    "# tests for developing the data cleaning for rows of duplicate symbols where some have data and some do not\n",
    "for symbol in errors:\n",
    "    dict_01 = dict()\n",
    "    indicies = stock_df_cleaned[stock_df_cleaned['Symbol'] == symbol].index\n",
    "    for index in indicies:\n",
    "        dict_01[index] = stock_df_cleaned.iloc[index, 13:34]    # create a dict where key is the index #, and the value is a tuple of values we're looking for\n",
    "    dict_02 = dict()    # this dict contains the index # as the key and the # of nan's in that row\n",
    "    for k, v in dict_01.items():\n",
    "        dict_02[k] = 0\n",
    "        for index, val in v.iteritems():\n",
    "            if isinstance(val, np.float64):\n",
    "                if (np.isnan(val)) == True:\n",
    "                    try: \n",
    "                        dict_02[k] = dict_02[k] + 1\n",
    "                    except:\n",
    "                        dict_02[k] = 1\n",
    "    least_nan = -1\n",
    "    least_nan_index = -1\n",
    "    for k, v in dict_02.items():    # see which k has the least # of nan's; that one will write to all of the other indicies\n",
    "        if least_nan == -1:\n",
    "            least_nan = v\n",
    "            least_nan_index = k\n",
    "        elif v < least_nan:\n",
    "            least_nan_index = k\n",
    "            least_nan = v\n",
    "    for index in indicies:\n",
    "        if least_nan_index != index:\n",
    "            stock_df_cleaned.iloc[index, 13:34] = stock_df_cleaned.iloc[least_nan_index, 13:34]\n",
    "            "
   ]
  },
  {
   "source": [
    "# Conditional Formatting\n",
    "\n",
    "## Apply Conditional Formatting to Values in certain columns\n",
    "\n",
    "\n",
    "Run this cell to apply condition formatting to specified columns throughout the document (such as Recognia Technical Analysis and P/E ratios). This cell also freezes the pane at C2 and autosizes the columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Color, PatternFill, Font\n",
    "from openpyxl.formatting import Rule\n",
    "from openpyxl.styles.differential import DifferentialStyle\n",
    "from openpyxl.formatting.rule import ColorScaleRule, CellIsRule, FormulaRule\n",
    "\n",
    "# load workbook\n",
    "wb = load_workbook(filename='target_workbook_030921_083456.xlsx')\n",
    "portfolio = wb.active\n",
    "num_rows = portfolio.max_row\n",
    "\n",
    "# formats fundamental analyses\n",
    "valuation_rule = ColorScaleRule(start_type='num', start_value=0, start_color='BE2525',\n",
    "mid_type='num', mid_value=50, mid_color='e5ff00',\n",
    "end_type='num', end_value=100, end_color='25BE25')\n",
    "\n",
    "portfolio.conditional_formatting.add(f'U2:U{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'V2:V{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'W2:W{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'X2:X{num_rows}', valuation_rule)\n",
    "\n",
    "# format total gain/loss percent\n",
    "portfolio.conditional_formatting.add(f'K2:K{num_rows}', ColorScaleRule(start_type='num', start_value=0, start_color='BE2525',\n",
    "mid_type='num', mid_value=4.5, mid_color='e5ff00',\n",
    "end_type='num', end_value=8, end_color='25BE25'))\n",
    "\n",
    "# format percentage of acct\n",
    "portfolio.conditional_formatting.add(f'L2:L{num_rows}', ColorScaleRule(start_type='num', start_value=0, start_color='25BE25',\n",
    "mid_type='num', mid_value=2.5, mid_color='e5ff00',\n",
    "end_type='num', end_value=3.5, end_color='be2525'))\n",
    "\n",
    "# equity summary score\n",
    "portfolio.conditional_formatting.add(f\"Q2:Q{num_rows}\", ColorScaleRule(start_type='num', start_value=0, start_color='be2525',\n",
    "mid_type='num', mid_value=5, mid_color='e5ff00',\n",
    "end_type='num', end_value=10, end_color='25be25'))\n",
    "\n",
    "# recognia technical analysis\n",
    "# if weak\n",
    "text_color_weak = Font(color='f9e9e9')\n",
    "text_highlight_weak = PatternFill(bgColor='be2525')\n",
    "dxf_weak = DifferentialStyle(font=text_color_weak, fill=text_highlight_weak)\n",
    "weak_rule = Rule(type='containsText', operator='containsText', text='weak', dxf=dxf_weak)\n",
    "weak_rule.formula = ['NOT(ISERROR(SEARCH(\"weak\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', weak_rule)\n",
    "\n",
    "# if neutral\n",
    "text_color_neutral = Font(color='000000')\n",
    "text_highlight_neutral = PatternFill(bgColor='e5ff00')\n",
    "dxf_neutral = DifferentialStyle(font=text_color_neutral, fill=text_highlight_neutral)\n",
    "neutral_rule = Rule(type='containsText', operator='containsText', text='neutral', dxf=dxf_neutral)\n",
    "neutral_rule.formula = ['NOT(ISERROR(SEARCH(\"neutral\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', neutral_rule)\n",
    "\n",
    "# if strong\n",
    "text_color_strong = Font(color='e9f9e9')\n",
    "text_highlight_strong = PatternFill(bgColor='25be25')\n",
    "dxf_strong = DifferentialStyle(font=text_color_strong, fill=text_highlight_strong)\n",
    "strong_rule = Rule(type='containsText', operator='containsText', text='strong', dxf=dxf_strong)\n",
    "strong_rule.formula = ['NOT(ISERROR(SEARCH(\"strong\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', strong_rule)\n",
    "\n",
    "# price target\n",
    "# if price target is greater than current price\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='greaterThan', formula=[f'E2:E{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='25be25',\n",
    "    end_color='25be25',\n",
    "    fill_type='solid'\n",
    ")))\n",
    "\n",
    "# if price target less than current price\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='lessThan', formula=[f'E2:E{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='be2525',\n",
    "    end_color='be2525',\n",
    "    fill_type='solid'\n",
    ")))\n",
    "\n",
    "# still trying to work out how to leave the blank cells blank\n",
    "'''# if none present\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='notContains', formula=[f'Y2:Y{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='FFFFFF',\n",
    "    end_color='FFFFFF',\n",
    "    fill_type='solid'\n",
    ")))'''\n",
    "\n",
    "# pe ratio, based on historic S&P 500 P/E ratio of 13-15\n",
    "# applying same rules to P/CF ratios\n",
    "portfolio.conditional_formatting.add(f'Z2:AC{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=13, start_color='25be25',\n",
    "    mid_type='num', mid_value=20, mid_color='e5ff00',\n",
    "    end_type='num', end_value=30, end_color='be2525'\n",
    "))\n",
    "\n",
    "# price to sales ratio\n",
    "portfolio.conditional_formatting.add(f'AD2:AE{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='25be25',\n",
    "    mid_type='num', mid_value=2, mid_color='e5ff00',\n",
    "    end_type='num', end_value=10, end_color='be2525'\n",
    "))\n",
    "\n",
    "# price to book ratio\n",
    "portfolio.conditional_formatting.add(f'AF2:AF{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='25be25',\n",
    "    mid_type='num', mid_value=1, mid_color='e5ff00',\n",
    "    end_type='num', end_value=3, end_color='be2525'\n",
    "))\n",
    "\n",
    "# debt to equity ratio\n",
    "portfolio.conditional_formatting.add(f'AG2:AH{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='25be25',\n",
    "    mid_type='num', mid_value=150, mid_color='e5ff00',\n",
    "    end_type='num', end_value=200, end_color='be2525'\n",
    "))\n",
    "\n",
    "# 52 Week Performance\n",
    "portfolio.conditional_formatting.add(f'AI2:AI{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='be2525',\n",
    "    mid_type='num', mid_value=4.5, mid_color='e5ff00',\n",
    "    end_type='num', end_value=8, end_color='25be25'\n",
    "))\n",
    "\n",
    "# freeze panes\n",
    "portfolio.freeze_panes = 'C2'\n",
    "\n",
    "# resize columns based on text, per stack overflow\n",
    "for column_cells in portfolio.columns:\n",
    "    length = max(len(str(cell.value)) for cell in column_cells)\n",
    "    portfolio.column_dimensions[column_cells[0].column_letter].width = length\n",
    "\n",
    "wb.save(\"target_workbook_030921_083456_formatted.xlsx\")"
   ]
  },
  {
   "source": [
    "# Visualization\n",
    "\n",
    "Coming soon!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
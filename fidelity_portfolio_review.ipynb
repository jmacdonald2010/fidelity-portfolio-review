{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Fidelity Portfolio Review\n",
    "### V 0.2.0\n",
    "\n",
    "## What does it do?\n",
    "\n",
    "This notebook imports data from a csv of account positions, copies the data into a new excel workbook, and fills in additional columns with additional information, such as P/E Ratios, Recognia Technical Analysis, etc.\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "This notebook uses the Selenium Webdriver to automate Firefox to navigate through Fidelity's stock research pages and extract useful information. \n",
    "\n",
    "After extracting the data, other cells can be run to clean the data, add conditional formatting to an excel document containing the data, and (coming soon) perform visualization with the data.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Selenium V 3.141.0\n",
    "- Gecko Webdriver installed in system path\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Matplotlib\n",
    "- Bokeh\n",
    "\n",
    "\n",
    "## Instructions for use\n",
    "\n",
    "1. From fidelity.com, log in and navigate to your account positions. Be sure you are viewing your positions with the Beta view (as of 3/13/2021). Click on the 'Share' icon, and click download. This will download a .csv of your account positions. Place this .csv file in the same folder as this notebook.\n",
    "\n",
    "2. In the first python code cell, replace the .csv file name with the name of your .csv file.\n",
    "\n",
    "3. Run the first cell to import the necessary libraries and modules and open a Firefox browser window that can be controlled by the Selenium Webdriver.\n",
    "\n",
    "4. Before running the next cell, log in to Fidelity as you normally would. The stock research data we're looking for is only available if you are logged into your account. No account information is gathered in the running of this cell.\n",
    "\n",
    "5. Run the data extraction cell. This will take some time, as there are pauses written in to avoid overloading the servers.\n",
    "\n",
    "6. Once the data extraction cell has finished running successfully, you can run the data cleaning cells (if necessary) and the visualization cells."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import extract\n",
    "import shutil\n",
    "\n",
    "def convert_to_float(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub('[\\$,%+]', '', value)\n",
    "        if value == \"--\":\n",
    "            value = np.nan\n",
    "    return np.float(value)\n",
    "\n",
    "# import the csv file:\n",
    "# change the file name to the name of your .csv file\n",
    "stock_df = pd.read_csv('your_data.csv', index_col=False)\n",
    "stock_df = stock_df.sort_values('Symbol')\n",
    "\n",
    "# add the necessary columns to the df for the data we will be extracting\n",
    "columns_list = ['Symbol', 'Description', 'Quantity', 'Last Price', 'Last Price Change', 'Current Value', \"Today's Gain/Loss Dollar\", \"Today's Gain/Loss Percent\", \"Total Gain/Loss Dollar\", \"Total Gain/Loss Percent\", \"Percent Of Account\", \"Cost Basis\", \"Cost Basis Per Share\", 'Div. Amt', 'Div. Yield', 'Equity Summary Score', 'Recognia Short Term', 'Recognia Intermediate Term', 'Recognia Long Term', 'Valuation', 'Quality', 'Growth Stability', 'Financial Health', '1-Yr Price Target', 'P/E TTM', 'P/E 5-Yr Avg', 'P/CF Recent Quarter', 'P/CF TTM', 'P/Sales Recent Quarter', 'P/Sales TTM', 'P/B', 'Debt/Equity TTM', 'Debt/Equity Recent Quarter', '52-Week Performance', \"Account Name/Number\"]\n",
    "stock_df = stock_df.reindex(columns = columns_list)\n",
    "\n",
    "current_time = datetime.now().strftime('%m%d%y_%H%M%S')\n",
    "new_workbook = f'target_workbook_{current_time}.xlsx'\n",
    "\n",
    "# next step: copy the existing data into the new excel document\n",
    "# we will be periodically overwriting this notebook\n",
    "# this will serve as backup for our data if the extract cell crashes\n",
    "stock_df.to_excel(new_workbook)\n",
    "\n",
    "# after that, open the web browser\n",
    "driver = Firefox()\n",
    "driver.get('https://www.fidelity.com/')\n",
    "driver.execute_script('''window.open(\"https://finance.yahoo.com/quote/V?p=V&.tsrc=fin-srch\", \"_blank\");''')\n",
    "fidelity_window = driver.window_handles[0]\n",
    "yf_window = driver.window_handles[1]\n",
    "driver.switch_to.window(window_name=fidelity_window)\n"
   ]
  },
  {
   "source": [
    "## Next,\n",
    "Log into Fidelity's website as you normally would. Once you have logged on to Fidelity's website, you can run the data extraction cell below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of symbols to iterate over\n",
    "# symbols = [i for i in stock_df['Symbol']]\n",
    "\n",
    "# define a prev_symbol variable to save time\n",
    "prev_symbol = \"\"\n",
    "\n",
    "# var set to control when to save to excel\n",
    "i = 0\n",
    "error_count = 0\n",
    "\n",
    "# iterate thru the symbols and write to the DF\n",
    "for row in stock_df.itertuples():\n",
    "    \n",
    "    if (stock_df.iloc[i, 33] > 0) | (stock_df.iloc[i, 33] < 0):\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    symbol = row[1]\n",
    "\n",
    "    if symbol == 'Pending Activity':\n",
    "        i += 1\n",
    "        continue\n",
    "    elif symbol == 'SPAXX**':\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # check to see if we already have data for the symbol\n",
    "\n",
    "        \n",
    "    # try/except block\n",
    "    # if we run into a 'NoSuchElementException', we go to the fidelity homepage, then try reloading the page\n",
    "    # the while loop is used in case of an error that causes the page to get reloaded; that way, it doesn't skip symbols and place data in the wrong place (hopefully)\n",
    "    \n",
    "    success = False\n",
    "\n",
    "    while success is False:\n",
    "    \n",
    "        try:\n",
    "\n",
    "            # load the page, and scroll thru it\n",
    "            driver.execute_script(\"window.scrollTo(0, 0)\")\n",
    "\n",
    "            driver.get(f\"https://snapshot.fidelity.com/fidresearch/snapshot/landing.jhtml#/research?symbol={symbol}&appCode=&optInNRE=\")\n",
    "            time.sleep(5)   # pauses may need to be adjusted based on network connection\n",
    "            driver.execute_script(\"window.scrollTo(0, 0)\")\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(\"window.scrollTo(0,(document.body.scrollHeight / 2))\")\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "\n",
    "            # now, check the security type\n",
    "            sec_type = extract.determine_security_type(driver)\n",
    "            if sec_type == 'Stocks':\n",
    "\n",
    "                # Dividends\n",
    "                dividends = extract.stock_div_yield(driver)\n",
    "                stock_df.at[row.Index, 'Div. Amt'] = dividends[0]\n",
    "                stock_df.at[row.Index, 'Div. Yield'] = dividends[1]\n",
    "\n",
    "                # Equity Summary Score\n",
    "                try:\n",
    "                    equity_sum_score = extract.stock_equity_sum_score(driver)\n",
    "                except:\n",
    "                    equity_sum_score = np.nan\n",
    "                stock_df.at[row.Index, 'Equity Summary Score'] = equity_sum_score\n",
    "\n",
    "                # Recognia Technical Analysis\n",
    "                recognia_dict = extract.recognia_analysis(driver, sec_type)\n",
    "                stock_df.loc[row.Index, 'Recognia Short Term'] = recognia_dict['Recognia Short Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Intermediate Term'] = recognia_dict['Recognia Intermediate Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Long Term'] = recognia_dict['Recognia Long Term']\n",
    "\n",
    "                # Stock Valuation\n",
    "                valuation = extract.stock_valuation(driver)\n",
    "                stock_df.at[row.Index, 'Valuation'] = valuation\n",
    "\n",
    "                # Stock Quality\n",
    "                quality = extract.stock_quality(driver)\n",
    "                stock_df.at[row.Index, 'Quality'] = quality\n",
    "\n",
    "                # Stock Growth Stability\n",
    "                growth_stability = extract.stock_growth_stability(driver)\n",
    "                stock_df.at[row.Index, 'Growth Stability'] = growth_stability\n",
    "\n",
    "                # Stock Financial Health\n",
    "                financial_health = extract.stock_financial_health(driver)\n",
    "                stock_df.at[row.Index, 'Financial Health'] = financial_health\n",
    "\n",
    "                # 52-Week Performance\n",
    "                ftw_perf = extract.stock_growth_stability(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # Key Stats\n",
    "                key_stats = extract.stock_key_stats(driver, symbol)\n",
    "                try: \n",
    "                    stock_df.at[row.Index, 'P/E TTM'] = key_stats[0]['P/E (Trailing Twelve Months)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/E 5-Yr Avg'] = key_stats[0]['P/E (5-Year Average)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E 5-Yr Avg'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF Recent Quarter'] = key_stats[0]['Price/Cash Flow (Most Recent Quarter)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF Recent Quarter'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF TTM'] = key_stats[0]['Price/Cash Flow (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales Recent Quarter'] = key_stats[0]['Price/Cash Flow (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales Recent Quarter'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales TTM'] = key_stats[0]['Price/Sales (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/B'] = key_stats[0]['Price/Book']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/B'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Debt/Equity TTM'] = key_stats[1]['Total Debt/Equity (Most Recent Quarter, Annualized)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Debt/Equity TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Debt/Equity Recent Quarter'] = key_stats[1]['Total Debt/Equity (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Debt/Equity Recent Quarter'] = np.nan\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 1-Yr Price Target\n",
    "                try:\n",
    "                    price_target = extract.stock_one_yr_price_target(driver, symbol)\n",
    "                except IndexError:\n",
    "                    price_target = np.nan\n",
    "                stock_df.at[row.Index, '1-Yr Price Target'] = price_target\n",
    "\n",
    "            elif sec_type == 'ETFs':\n",
    "                \n",
    "                # ETF Stats\n",
    "                etf_stats = extract.etf_key_stats(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/E TTM'] = etf_stats['Price / Earnings (TTM)']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/E TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/B'] = etf_stats['Price / Book']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/B'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/Sales TTM'] = etf_stats['Price / Sales']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/Sales TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'P/CF TTM'] = etf_stats['Price / Cash Flow']\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'P/CF TTM'] = np.nan\n",
    "                try:\n",
    "                    stock_df.at[row.Index, 'Div. Yield'] = etf_stats['etf_distribution_yield']  # changed this recently to better reflect what the actual function returns\n",
    "                except:\n",
    "                    stock_df.loc[row.Index, 'Div. Yield'] = np.nan\n",
    "\n",
    "                # ETF Recognia\n",
    "                try:\n",
    "                    recognia_dict = extract.recognia_analysis(driver, sec_type)\n",
    "                except IndexError:\n",
    "                    recognia_dict = {\n",
    "                        'Recognia Short Term': np.nan,\n",
    "                        'Recognia Intermediate Term': np.nan,\n",
    "                        'Recognia Long Term': np.nan\n",
    "                    }\n",
    "                stock_df.loc[row.Index, 'Recognia Short Term'] = recognia_dict['Recognia Short Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Intermediate Term'] = recognia_dict['Recognia Intermediate Term']\n",
    "                stock_df.loc[row.Index, 'Recognia Long Term'] = recognia_dict['Recognia Long Term']\n",
    "\n",
    "                # ETF 52 Week Performance\n",
    "                ftw_perf = extract.etf_52_week_perf(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except ValueError:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "            elif sec_type == 'Mutual Funds':\n",
    "\n",
    "                # 52 Week Performance\n",
    "                ftw_perf = extract.mf_52_week_perf(driver)\n",
    "                try:\n",
    "                    stock_df.at[row.Index, '52-Week Performance'] = ftw_perf\n",
    "                except ValueError:\n",
    "                    stock_df.loc[row.Index, '52-Week Performance'] = np.nan\n",
    "\n",
    "        \n",
    "            success = True\n",
    "            i += 1\n",
    "            if (i % 5) == 0:\n",
    "                stock_df.to_excel(new_workbook)\n",
    "                print('DF saved to Excel File')\n",
    "            prev_symbol = symbol\n",
    "            # prev_series = stock_df.iloc[row.Index, 13:34]\n",
    "            prev_row = row.Index\n",
    "            error_count = 0\n",
    "\n",
    "        except (NoSuchElementException, IndexError) as e:\n",
    "            driver.get(\"https://www.fidelity.com/\")\n",
    "            time.sleep(10)\n",
    "            error_count += 1\n",
    "            if error_count > 3:\n",
    "                i += 1\n",
    "                success = True\n",
    "stock_df.to_excel(new_workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reopen the browser in case of a crash:\n",
    "driver = Firefox()\n",
    "driver.get('https://www.fidelity.com/')\n",
    "driver.execute_script('''window.open(\"https://finance.yahoo.com/quote/V?p=V&.tsrc=fin-srch\", \"_blank\");''')\n",
    "fidelity_window = driver.window_handles[0]\n",
    "yf_window = driver.window_handles[1]\n",
    "driver.switch_to.window(window_name=fidelity_window)"
   ]
  },
  {
   "source": [
    "# Data Cleaning Cells\n",
    "\n",
    "These cells are used to normalize the data, removing dollar signs, commas, or complete inconsistent data for duplicate symbols."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load Workbook\n",
    "\n",
    "Run the cell below if you are doing your data cleaning/visualization in a different session from your original data extraction with Selenium."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is to only be used if you are doing your cleaning/analysis in a different session from extracting your data.\n",
    "\n",
    "# if you need to reopen your workbook later for further analysis, run this cell\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from datetime import datetime\n",
    "import extract\n",
    "import shutil\n",
    "\n",
    "def convert_to_float(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub('[\\$,%+]', '', value)\n",
    "        if value == \"--\":\n",
    "            value = np.nan\n",
    "    return np.float(value)\n",
    "\n",
    "# change new_workbook variable to the filename for your .xlsx file\n",
    "new_workbook = 'your_data.xlsx'\n",
    "stock_df = pd.read_excel(new_workbook, 'Sheet1')"
   ]
  },
  {
   "source": [
    "## Convert strings to np.floats\n",
    "\n",
    "Run the cell below to normalize the data in your dataframe/excel document by converting the data from the original .csv file to np.floats."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to convert the strings from the fidelity sheet to np.floats\n",
    "\n",
    "def convert_to_float(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub('[\\$,%+]', '', value)\n",
    "        if value == \"--\":\n",
    "            value = np.nan\n",
    "    return np.float(value)\n",
    "\n",
    "stock_df_cleaned = stock_df.copy()\n",
    "try:\n",
    "    stock_df_cleaned = stock_df_cleaned.drop(columns=['Unnamed: 0'])    # this is for when the file is manually reloaded, as it occasionally creates duplicate unnecessary columns that cause problems\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    stock_df_cleaned = stock_df_cleaned.drop(columns=['Unnamed: 0.1'])\n",
    "except:\n",
    "    pass\n",
    "for i in range(3, 13):\n",
    "    stock_df_cleaned.iloc[:, i] = stock_df_cleaned.apply(lambda x: convert_to_float(x[i]), axis=1)\n",
    "stock_df_cleaned.to_excel(new_workbook)"
   ]
  },
  {
   "source": [
    "## Missing Data\n",
    "\n",
    "If you notice that data inconsistencies between rows of the same symbol, this cell aims to correct that by taking the row with the least np.nan's and copying its data to the other rows of the same symbol. Do not run this if your data is already consistent.\n",
    "\n",
    "Next, Look through the data and ensure that any symbol that appears twice has the same extracted data in each row. \n",
    "\n",
    "## **If you have consistent data for duplicate symbols, you do not need to run this cell.**\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks for rows where the same symbol have missing values from the webscraped data, and copies the data from the row w/ the least nan values.\n",
    "\n",
    "# compile a list of symbols that fit this criteria\n",
    "errors = []\n",
    "prev_symbol = ''\n",
    "for row in stock_df_cleaned.itertuples():\n",
    "    symbol = row[1]\n",
    "    if symbol == 'Pending Activity':\n",
    "        continue\n",
    "    elif symbol == 'SPAXX**':\n",
    "        continue\n",
    "    row_data = row[14:35]\n",
    "    if symbol == prev_symbol:\n",
    "        if row[0] == 1:\n",
    "            prev_symbol = symbol\n",
    "            prev_row_data = row_data\n",
    "            continue\n",
    "        for i in range(0, len(row_data)):\n",
    "            if row_data[i] != prev_row_data[i]:\n",
    "                if symbol not in errors:\n",
    "                    errors.append(symbol)\n",
    "                break\n",
    "    prev_symbol = symbol\n",
    "    prev_row_data = row_data\n",
    "\n",
    "# go through this list and copy the data appropriately\n",
    "# tests for developing the data cleaning for rows of duplicate symbols where some have data and some do not\n",
    "for symbol in errors:\n",
    "    dict_01 = dict()\n",
    "    indicies = stock_df_cleaned[stock_df_cleaned['Symbol'] == symbol].index\n",
    "    for index in indicies:\n",
    "        dict_01[index] = stock_df_cleaned.iloc[index, 13:34]    # create a dict where key is the index #, and the value is a tuple of values we're looking for\n",
    "    dict_02 = dict()    # this dict contains the index # as the key and the # of nan's in that row\n",
    "    for k, v in dict_01.items():\n",
    "        dict_02[k] = 0\n",
    "        for index, val in v.iteritems():\n",
    "            if isinstance(val, np.float64):\n",
    "                if (np.isnan(val)) == True:\n",
    "                    try: \n",
    "                        dict_02[k] = dict_02[k] + 1\n",
    "                    except:\n",
    "                        dict_02[k] = 1\n",
    "    least_nan = -1\n",
    "    least_nan_index = -1\n",
    "    for k, v in dict_02.items():    # see which k has the least # of nan's; that one will write to all of the other indicies\n",
    "        if least_nan == -1:\n",
    "            least_nan = v\n",
    "            least_nan_index = k\n",
    "        elif v < least_nan:\n",
    "            least_nan_index = k\n",
    "            least_nan = v\n",
    "    for index in indicies:\n",
    "        if least_nan_index != index:\n",
    "            stock_df_cleaned.iloc[index, 13:34] = stock_df_cleaned.iloc[least_nan_index, 13:34]\n",
    "            "
   ]
  },
  {
   "source": [
    "# Conditional Formatting\n",
    "\n",
    "## Apply Conditional Formatting to Values in certain columns\n",
    "\n",
    "\n",
    "Run this cell to apply condition formatting to specified columns throughout the document (such as Recognia Technical Analysis and P/E ratios). This cell also freezes the pane at C2 and autosizes the columns.\n",
    "\n",
    "KNOWN ERROR: Due to some of the extra information at the bottom of the original Fidelity .csv, this greatly missizes the \"Account\" column in the excel document. A fix will be provided in a later version. It is also known that the price-target conditional formatting fills the blank cells with red. A future version will leave these cells blank."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Color, PatternFill, Font\n",
    "from openpyxl.formatting import Rule\n",
    "from openpyxl.styles.differential import DifferentialStyle\n",
    "from openpyxl.formatting.rule import ColorScaleRule, CellIsRule, FormulaRule\n",
    "\n",
    "# load workbook\n",
    "wb = load_workbook(filename='target_workbook_030921_083456.xlsx')\n",
    "portfolio = wb.active\n",
    "num_rows = portfolio.max_row\n",
    "\n",
    "# formats fundamental analyses\n",
    "valuation_rule = ColorScaleRule(start_type='num', start_value=0, start_color='BE2525',\n",
    "mid_type='num', mid_value=50, mid_color='e5ff00',\n",
    "end_type='num', end_value=100, end_color='25BE25')\n",
    "\n",
    "portfolio.conditional_formatting.add(f'U2:U{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'V2:V{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'W2:W{num_rows}', valuation_rule)\n",
    "portfolio.conditional_formatting.add(f'X2:X{num_rows}', valuation_rule)\n",
    "\n",
    "# format total gain/loss percent\n",
    "portfolio.conditional_formatting.add(f'K2:K{num_rows}', ColorScaleRule(start_type='num', start_value=0, start_color='BE2525',\n",
    "mid_type='num', mid_value=4.5, mid_color='e5ff00',\n",
    "end_type='num', end_value=8, end_color='25BE25'))\n",
    "\n",
    "# format percentage of acct\n",
    "portfolio.conditional_formatting.add(f'L2:L{num_rows}', ColorScaleRule(start_type='num', start_value=0, start_color='25BE25',\n",
    "mid_type='num', mid_value=2.5, mid_color='e5ff00',\n",
    "end_type='num', end_value=3.5, end_color='be2525'))\n",
    "\n",
    "# equity summary score\n",
    "portfolio.conditional_formatting.add(f\"Q2:Q{num_rows}\", ColorScaleRule(start_type='num', start_value=0, start_color='be2525',\n",
    "mid_type='num', mid_value=5, mid_color='e5ff00',\n",
    "end_type='num', end_value=10, end_color='25be25'))\n",
    "\n",
    "# recognia technical analysis\n",
    "# if weak\n",
    "text_color_weak = Font(color='f9e9e9')\n",
    "text_highlight_weak = PatternFill(bgColor='be2525')\n",
    "dxf_weak = DifferentialStyle(font=text_color_weak, fill=text_highlight_weak)\n",
    "weak_rule = Rule(type='containsText', operator='containsText', text='weak', dxf=dxf_weak)\n",
    "weak_rule.formula = ['NOT(ISERROR(SEARCH(\"weak\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', weak_rule)\n",
    "\n",
    "# if neutral\n",
    "text_color_neutral = Font(color='000000')\n",
    "text_highlight_neutral = PatternFill(bgColor='e5ff00')\n",
    "dxf_neutral = DifferentialStyle(font=text_color_neutral, fill=text_highlight_neutral)\n",
    "neutral_rule = Rule(type='containsText', operator='containsText', text='neutral', dxf=dxf_neutral)\n",
    "neutral_rule.formula = ['NOT(ISERROR(SEARCH(\"neutral\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', neutral_rule)\n",
    "\n",
    "# if strong\n",
    "text_color_strong = Font(color='e9f9e9')\n",
    "text_highlight_strong = PatternFill(bgColor='25be25')\n",
    "dxf_strong = DifferentialStyle(font=text_color_strong, fill=text_highlight_strong)\n",
    "strong_rule = Rule(type='containsText', operator='containsText', text='strong', dxf=dxf_strong)\n",
    "strong_rule.formula = ['NOT(ISERROR(SEARCH(\"strong\",R2)))']\n",
    "portfolio.conditional_formatting.add(f'R2:T{num_rows}', strong_rule)\n",
    "\n",
    "# price target\n",
    "# if price target is greater than current price\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='greaterThan', formula=[f'E2:E{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='25be25',\n",
    "    end_color='25be25',\n",
    "    fill_type='solid'\n",
    ")))\n",
    "\n",
    "# if price target less than current price\n",
    "portfolio.conditional_formatting.add(f'Y2:Y{num_rows}',\n",
    "CellIsRule(operator='lessThan', formula=[f'E2:E{num_rows}'], stopIfTrue=True, fill=PatternFill(\n",
    "    start_color='be2525',\n",
    "    end_color='be2525',\n",
    "    fill_type='solid'\n",
    ")))\n",
    "\n",
    "# pe ratio, based on historic S&P 500 P/E ratio of 13-15\n",
    "# applying same rules to P/CF ratios\n",
    "portfolio.conditional_formatting.add(f'Z2:AC{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=13, start_color='25be25',\n",
    "    mid_type='num', mid_value=20, mid_color='e5ff00',\n",
    "    end_type='num', end_value=30, end_color='be2525'\n",
    "))\n",
    "\n",
    "# price to sales ratio\n",
    "portfolio.conditional_formatting.add(f'AD2:AE{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='25be25',\n",
    "    mid_type='num', mid_value=2, mid_color='e5ff00',\n",
    "    end_type='num', end_value=10, end_color='be2525'\n",
    "))\n",
    "\n",
    "# price to book ratio\n",
    "portfolio.conditional_formatting.add(f'AF2:AF{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='25be25',\n",
    "    mid_type='num', mid_value=1, mid_color='e5ff00',\n",
    "    end_type='num', end_value=3, end_color='be2525'\n",
    "))\n",
    "\n",
    "# debt to equity ratio\n",
    "portfolio.conditional_formatting.add(f'AG2:AH{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='25be25',\n",
    "    mid_type='num', mid_value=150, mid_color='e5ff00',\n",
    "    end_type='num', end_value=200, end_color='be2525'\n",
    "))\n",
    "\n",
    "# 52 Week Performance\n",
    "portfolio.conditional_formatting.add(f'AI2:AI{num_rows}', ColorScaleRule(\n",
    "    start_type='num', start_value=0, start_color='be2525',\n",
    "    mid_type='num', mid_value=4.5, mid_color='e5ff00',\n",
    "    end_type='num', end_value=8, end_color='25be25'\n",
    "))\n",
    "\n",
    "# freeze panes\n",
    "portfolio.freeze_panes = 'C2'\n",
    "\n",
    "# resize columns based on text, per stack overflow\n",
    "for column_cells in portfolio.columns:\n",
    "    length = max(len(str(cell.value)) for cell in column_cells)\n",
    "    portfolio.column_dimensions[column_cells[0].column_letter].width = length\n",
    "\n",
    "wb.save(\"target_workbook_030921_083456_formatted.xlsx\")"
   ]
  },
  {
   "source": [
    "# Visualization\n",
    "\n",
    "The cells below perform visualizations comparing various analyses and technical indicators across different symbols. Some cells (such as Total Gain/Loss) show all symbols in your accounts, including duplicates, whereas others (such as Equity Summary Score) remove duplicates."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## First, run the import cell below\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may not be necessary as I'm mainly using the plotting built-in to pandas\n",
    "# consider removing in a future version.\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "## Next, run the cells below to see different visualizations of information about your holdings."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Total Gain/Loss, Percent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Gain/Loss, omitting blank bars from chart by making a new df\n",
    "tgl_df_01 = stock_df_cleaned.copy()\n",
    "tgl_df_01 = tgl_df_01[tgl_df_01['Total Gain/Loss Percent'].notna()]\n",
    "tgl_df_01.plot.bar(x=\"Symbol\", y=\"Total Gain/Loss Percent\", figsize=(100,9), grid=True, title='Total Gain/Loss (Percent)', fontsize=18)"
   ]
  },
  {
   "source": [
    "### Total Gain/Loss, Percent, vs. 52-Week Performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot, gain/loss vs. 52-week performance\n",
    "tgl_df_01.plot.bar(x='Symbol', y=[\"Total Gain/Loss Percent\", \"52-Week Performance\"], figsize=(150,20), grid=True, title=\"Total Gain/Loss vs. 52-Week Performance\", fontsize=18)"
   ]
  },
  {
   "source": [
    "### Recognia Technical Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping a new df where recognia is based on numbers, 1 for weak, 2 for neutral, 3 for strong\n",
    "def convert_recognia(value, **kwargs):\n",
    "    if isinstance(value, str):\n",
    "        if value == 'weak':\n",
    "            value = np.int(1)\n",
    "        elif value == 'neutral':\n",
    "            value = np.int(2)\n",
    "        elif value == 'strong':\n",
    "            value = np.int(3)\n",
    "        else:\n",
    "            value = np.int(0)\n",
    "    return np.float(value)\n",
    "# dataframe_recogniaFloatforPlot\n",
    "df_rfp = stock_df_cleaned.copy()\n",
    "df_rfp = df_rfp.drop_duplicates(subset=['Symbol'])\n",
    "for i in range(16, 19):\n",
    "    df_rfp.iloc[:, i] = df_rfp.apply(lambda x: convert_recognia(x[i]), axis=1)\n",
    "\n",
    "df_rfp = df_rfp[df_rfp['Recognia Short Term'].notna()]\n",
    "\n",
    "df_rfp.plot.bar(x=\"Symbol\", y=[\"Recognia Short Term\", \"Recognia Intermediate Term\", \"Recognia Long Term\"], figsize=(175, 15), grid=True, title=\"Recognia Technical Analysis\", fontsize=18)"
   ]
  },
  {
   "source": [
    "### Key Stats"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key stats\n",
    "ks_df = stock_df_cleaned.copy()\n",
    "\n",
    "ks_df = ks_df[ks_df['P/B'].notna()] # w/ the portfolio I have tested this code w/, every security w/ any key stats at least had a P/B ratio.\n",
    "ks_df = ks_df.drop_duplicates(subset=['Symbol'])\n",
    "\n",
    "ks_df.plot.bar(x=\"Symbol\", y=['P/E TTM', 'P/E 5-Yr Avg', 'P/CF Recent Quarter', 'P/CF TTM', 'P/Sales Recent Quarter', 'P/Sales TTM', 'P/B'], figsize=(200, 15), grid=True, title=\"Key Stats\", ylim=(-5, 70), fontsize=18)"
   ]
  },
  {
   "source": [
    "### Fundamental Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental Analysis\n",
    "fa_df = stock_df_cleaned.copy()\n",
    "fa_df = fa_df[fa_df['Valuation'].notna()]\n",
    "fa_df = fa_df.drop_duplicates(subset=[\"Symbol\"])\n",
    "\n",
    "fa_df.plot.bar(x=\"Symbol\", y=['Valuation', 'Quality', 'Growth Stability', 'Financial Health'], figsize=(100, 15), grid=True, title='Fundamental Analysis', ylim=(0, 100), fontsize=18)"
   ]
  },
  {
   "source": [
    "### Equity Summary Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equity Summary Score\n",
    "ess_df = stock_df_cleaned.copy()\n",
    "ess_df = ess_df[ess_df[\"Equity Summary Score\"].notna()]\n",
    "ess_df = ess_df.drop_duplicates(subset=[\"Symbol\"])\n",
    "\n",
    "ess_df.plot.bar(x='Symbol', y='Equity Summary Score', figsize=(75, 10), grid=True, title='Equity Summary Score', ylim=(0, 10), fontsize=18)"
   ]
  },
  {
   "source": [
    "### Price change percentage over time vs. SPY\n",
    "\n",
    "Change the symbol variable from 'NXST' to the security you'd like to visualize.\n",
    "\n",
    "Change the period variable from '2y' to the time period you'd like to visualize (see code cell for valid time periods)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a security's performance to that of the S&P 500\n",
    "import yfinance as yf\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "def pct_change(df):\n",
    "    df['Close'] = (df.iloc[0].Close / df.Close)\n",
    "    return df\n",
    "\n",
    "def close_change(df):\n",
    "    i = 0\n",
    "    for row in df.itertuples():\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            df.iloc[i, 3] = 100 * ( 1 - (df.iloc[0, 3] / df.iloc[i, 3]))\n",
    "            i += 1\n",
    "    df.iloc[0, 3] = np.nan\n",
    "    return df\n",
    "\n",
    "\n",
    "# change the symbol variable to the security you'd like to look up\n",
    "symbol = 'NXST'\n",
    "\n",
    "# change the time frame you'd like to compare the two over\n",
    "# valid times are 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max\n",
    "# intervals are 1m, 2m, 5m, 15m, 30m, 60m, 90m, 1h, 1d, 5d, 1wk, 1mo, 3mo (intraday does not extend past 60 days)\n",
    "period = '2y'\n",
    "interval = '1d'\n",
    "\n",
    "stock = yf.Ticker(symbol)\n",
    "spy = yf.Ticker('SPY')  # just uses the SPY ETF\n",
    "\n",
    "stock = stock.history(period=period, interval=interval)\n",
    "spy = spy.history(period=period, interval=interval)\n",
    "\n",
    "\n",
    "# data = yf.download(\"AAPL SPY\", period=period, interval=interval)\n",
    "\n",
    "# get data ready\n",
    "#stock = stock.groupby('Date')['Close'].apply(pct_change)\n",
    "#spy = spy.groupby('Date')['Close'].apply(pct_change)\n",
    "\n",
    "stock = close_change(stock)\n",
    "spy = close_change(spy)\n",
    "\n",
    "# create ColumnDataSource objects for each security\n",
    "stock_cds = ColumnDataSource(stock)\n",
    "spy_cds = ColumnDataSource(spy)\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "fig = figure(x_axis_type='datetime',\n",
    "plot_height=300, plot_width=600,\n",
    "title=f'{symbol} vs. SPY',\n",
    "x_axis_label='DateTime', y_axis_label='Price Percent Change')\n",
    "\n",
    "fig.line('Date', 'Close', source=stock_cds, line_color='red', legend_label=f'{symbol}')\n",
    "fig.line('Date', 'Close', source=spy_cds, line_color='blue', legend_label='SPY')\n",
    "fig.legend.location = 'top_left'\n",
    "fig.legend.click_policy = 'hide'\n",
    "\n",
    "# fig.multiline()\n",
    "\n",
    "show(fig)\n"
   ]
  }
 ]
}